version: "3"

services:
  spark-master:
    container_name: spark-master
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_LOCAL_IP=spark-master
      - SPARK_DRIVER_MEMORY=8G
      - KAFKA_TOPIC_NAME=streaming
      - KAFKA_SERVER=kafka
      - KAFKA_PORT=29092
    ports:
      - "8000:8000"
      - "8090:8080"
      - "7077:7077"
      - "4040:4040"
      - "5000:5000"
    expose:
      - "7077"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./:/opt/spark/spark_script
    links:
      - rtmp-stream-server
    tty: true

  spark-worker-1:
    container_name: spark-worker-1
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=8G
      - SPARK_WORKER_CORES=4
      - SPARK_DRIVER_MEMORY=8G
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_LOCAL_IP=spark-worker-1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./:/opt/spark/spark_script
    tty: true

  spark-worker-2:
    container_name: spark-worker-2
    build:
      context: .
      dockerfile: Dockerfile
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=8G
      - SPARK_WORKER_CORES=4
      - SPARK_DRIVER_MEMORY=8G
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_LOCAL_IP=spark-worker-2
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./:/opt/spark/spark_script
    tty: true
  
  rtmp-stream-server: 
    container_name: rtmp-server
    build:
      context: .
      dockerfile: Dockerfile.rtmpserver
    ports:
      - "1935:1935"
    expose:
      - "1935"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./utils:/opt/spark/utils
    tty: true

  # zookeeper:
  #   image: confluentinc/cp-zookeeper:6.2.0
  #   container_name: zookeeper
  #   # networks:
  #   #   - broker-kafka
  #   ports:
  #     - "2181:2181"
  #   environment:
  #     ZOOKEEPER_CLIENT_PORT: 2181
  #     ZOOKEEPER_TICK_TIME: 2000

  # kafka:
  #   image: confluentinc/cp-kafka:6.2.0
  #   container_name: kafka
  #   # networks:
  #   #   - broker-kafka
  #   depends_on:
  #     - zookeeper
  #   ports:
  #     - "9092:9092"
  #     - "9101:9101"
  #   environment:
  #     KAFKA_BROKER_ID: 1
  #     KAFKA_ADVERTISED_HOST_NAME: kafka:9092
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
  #     KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
  #     # KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #     # KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
  #     # KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
  #     # KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
  #     # KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
  #     # KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

  # kafdrop:
  #   image: obsidiandynamics/kafdrop:3.27.0
  #   # networks:
  #   #   - broker-kafka
  #   depends_on:
  #     - kafka
  #     - zookeeper
  #   ports:
  #     - 19000:9000
  #   environment:
  #     KAFKA_BROKERCONNECT: kafka:29092

  # consumer:
  #   container_name: consumer
  #   build:
  #     context: ./consumers
  #     dockerfile: Dockerfile
  #   environment:
  #     - KAFKA_TOPIC_NAME=streaming
  #     - KAFKA_SERVER=kafka
  #     - KAFKA_PORT=29092
  #   ports:
  #     - "8001:8001"
  #     - "9090:9090"
  #   expose:
  #     - 9090
  #   volumes:
  #     - ./consumers/:/consumers
  #   depends_on:
  #     - zookeeper
  #     - kafka
  #     - spark-master
  #   # networks:
  #   #   - broker-kafka
  #   tty: true

  # publisher:
  #   container_name: publisher
  #   build:
  #     context: ./main
  #     dockerfile: Dockerfile
  #   environment:
  #     - KAFKA_TOPIC_NAME=topic_test
  #     - KAFKA_SERVER=kafka
  #     - KAFKA_PORT=29092
  #   volumes:
  #     - ./main:/opt/spark/spark_scripts
  #   ports:
  #     - 8000:8000
  #   restart: "always"
  #   depends_on:
  #     - zookeeper
  #     - kafka
  #   networks:
  #     - broker-kafka

volumes:
  spark_script:
# networks:
#   broker-kafka:
#     driver: bridge
